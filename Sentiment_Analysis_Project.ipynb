{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1wHtyBBjkp-",
        "outputId": "94f27635-4a92-4056-c987-b93d127cb741"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITYce7jAjQoS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EumZx9qPjQoV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lMHDFDdKjQoW"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4-Z9B6MRjQoY"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiqCalzHjQoZ",
        "outputId": "7ae3e8ec-a04f-405b-e032-a1576f987a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IFJ1DWgAjQoa"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_CHOICE = 'spacy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I3tXM3H_jQoa"
      },
      "outputs": [],
      "source": [
        "if TOKENIZER_CHOICE == 'spacy':\n",
        "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "    def tokenizer(text):\n",
        "        return [tok.text.lower() for tok in spacy_en.tokenizer(text) if tok.text.isalpha() and tok.text not in stop_words]\n",
        "else:\n",
        "    def tokenizer(text):\n",
        "        return [word.lower() for word in nltk.word_tokenize(text) if word.isalpha() and word not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mBzOr9LSjQob"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def load_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = pd.read_csv(csv_file, usecols=['review', 'sentiment'])\n",
        "    df.dropna(inplace=True)\n",
        "    df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df['tokens'] = df['review'].apply(tokenizer)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYQts82fjQob",
        "outputId": "a5e9af25-f91c-4638-d412-f323459b76ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "glove = api.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4m0-TRyfjQoc"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(vocab):\n",
        "    embedding_dim = 300\n",
        "    embedding_matrix = torch.zeros(len(vocab) + 1, embedding_dim)\n",
        "    for word, i in vocab.items():\n",
        "        if word in glove:\n",
        "            embedding_matrix[i] = torch.tensor(glove[word], dtype=torch.float32)\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tv_0RnaTjQoc"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, df, vocab):\n",
        "        self.data = df\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.data.iloc[idx]['tokens']\n",
        "        label = self.data.iloc[idx]['label']\n",
        "        indexed = [self.vocab.get(word, 0) for word in tokens]\n",
        "        return torch.tensor(indexed, dtype=torch.long), torch.tensor(label, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nadW0PeijQod"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)\n",
        "    inputs = [torch.tensor(seq, dtype=torch.long) for seq in inputs]\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    return inputs_padded, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HVooPb5ajQod"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, embedding_weights=None):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding.weight.data.copy_(embedding_weights)\n",
        "            self.embedding.weight.requires_grad = False\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
        "        self.batch_norm = nn.BatchNorm1d(hidden_dim * 2 if bidirectional else hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1) if self.rnn.bidirectional else hidden[-1,:,:]\n",
        "        hidden = self.batch_norm(hidden)\n",
        "        return self.fc(hidden)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    return correct.sum() / len(correct)"
      ],
      "metadata": {
        "id": "PwJBZam32DOM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m2W-zV-NjQoe"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(params, embedding_matrix, train_loader, val_loader, test_loader, vocab_size, patience=3):\n",
        "    model = SentimentRNN(vocab_size, params['embedding_dim'], params['hidden_dim'], 1, params['n_layers'], params['bidirectional'], params['dropout'], embedding_matrix).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
        "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs).squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "            if torch.isnan(loss):\n",
        "                continue\n",
        "            acc = binary_accuracy(predictions, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "        val_loss, val_acc = 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                predictions = model(inputs).squeeze(1)\n",
        "                loss = criterion(predictions, labels)\n",
        "                if torch.isnan(loss):\n",
        "                    continue\n",
        "                acc = binary_accuracy(predictions, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_acc += acc.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc /= len(val_loader)\n",
        "        print(f'Epoch {epoch+1}: Train Loss = {epoch_loss / len(train_loader):.4f}, Train Acc = {epoch_acc / len(train_loader):.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}')\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            predictions = model(inputs).squeeze(1)\n",
        "            correct += (torch.round(torch.sigmoid(predictions)) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "kcUwKTRF4Nw_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z5ZUBWD7jQoe"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'embedding_dim': [300],\n",
        "    'hidden_dim': [256],\n",
        "    'n_layers': [4],\n",
        "    'bidirectional': [True],\n",
        "    'dropout': [0.2, 0.5],\n",
        "    'lr': [0.001, 0.0005]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fcpHzAg-jQoe"
      },
      "outputs": [],
      "source": [
        "df = load_data('IMDB_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8ao5FXiojQof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ece0a6ec-4a69-4c65-9f6d-d86917e80e2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  label\n",
              "0  One of the other reviewers has mentioned that ...  positive    1.0\n",
              "1  A wonderful little production. <br /><br />The...  positive    1.0\n",
              "2  I thought this was a wonderful way to spend ti...  positive    1.0\n",
              "3  Basically there's a family where a little boy ...  negative    0.0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive    1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e563b0-83f3-44f4-a406-ff31c41668a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e563b0-83f3-44f4-a406-ff31c41668a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88e563b0-83f3-44f4-a406-ff31c41668a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88e563b0-83f3-44f4-a406-ff31c41668a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e3cf6a7-eeb0-42da-aa08-962ea3d63087\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e3cf6a7-eeb0-42da-aa08-962ea3d63087')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e3cf6a7-eeb0-42da-aa08-962ea3d63087 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 49999,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49581,\n        \"samples\": [\n          \"Poorly done political actioner. Badly photographed, acted, and directed. Every single scene is underlighted, including those very few that are shot during the daytime. It doesn't matter what the location is. At an important conference in the White House, no lights are on, and the only available lighting is a gloomy blue that is filtered through a few windows. The primier of China conducts an earth-shattering phone conversation under conditions of such intense chiaroscuro that he should be contemplating a bust of Homer in a Rembrandt painting. Honest. It's as if he had a tiny spotlight on his face and was otherwise in total darkness. The slow motion deaths are by now obligatory in any ill-thought-out movie.<br /><br />Roy Scheider and Maria Conchita Alonzo do well by their roles, but Scheider is rarely on screen. The other performances are dismissable. There is a pretty Oriental woman in a short tight skirt who totes a gun and is right out of a Bond movie who's accent suggests a childhood spent in Basset, Nebraska, and who should have remained the model she probably started out as. Whoever plays the surviving Secret Service agent aboard the cruise ship was probably picked for the part because he looked most like Johnny Depp, not because of any display of talent. The Chinese villains, representing both Taiwan and mainland China, hiss and grin as they threaten the heroes. <br /><br />The script is pretty awful, recycled from other, better films. There is a lot of shooting aboard the ship and practically everyone winds up mincemeat. Two thirds of the way through, the ship explodes into the expected series of fireballs. Then the movie splits into two related parts. Part one, another shootout, this time in a waterfront warehouse. Part two, an exchange between the Vice President, now acting president, and the oily Chinese premiere, lifted out of both \\\"Dr. Strangelove\\\" and \\\"Fail Safe.\\\" We unwittingly launch our missiles. They launch theirs in retaliation. We cannot convince them that our launch was accidental, even though we offer to help them destroy our own missiles. There is even the George C. Scott/ Walter Matthau general who argues that their \\\"nucular\\\" armory can't match ours so we should hit them with everything we've got. More fireballs. <br /><br />The end comes none too soon.\",\n          \"Not good. Mostly because you don't give a damn about what happens to all these people. Some comments : 1. I am tired of seeing governesses who never talk to their pupils, never teach them anything and take a tired and annoyed look whenever the said pupil, who of course has been won over in the space of 4 seconds, says something 2. Fine, so Rosina has a father complex and therefore is attracted to her employer. But Charles is completely different in all aspects from her father - if anything Henry is much closer as a sensual, exalted person 3. How could you ever believe that she would be more attracted to Tom Wilkinson than to Rhys Meyer. 4. Hard to believe, if she had been in fact raised as a deeply religious girl, that she would be so careless about sleeping with a gentile after knowing him for 5 minutes.<br /><br />Some good things about the film : At least she didn't end up pregnant, not knowing who the father was... The whole description of life in the Jewish community in London is good\",\n          \"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s (the origins of Off Off Broadway). Though it's not for everyone, it is a genuinely brilliant, darkly funny, even more often deeply disturbing tale about love, sex, personal liberty, and revenge, a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution. The story is not about being gay, though -- it's about love and sex that don't conform to social norms and therefore must be removed through violence and hate. On the surface, it tells the story of a man who falls in love with a pig, but like any great fable, it's not really about animals, it's about something bigger -- stifling conformity in America.<br /><br />The stage version won international acclaim in its original production, it toured the U.S. and Europe, and with others of its kind, influenced almost all theatre that came after it. Luckily, we have preserved here the show pretty much as it was originally conceived, with the original cast and original director, Tom O'Horgan (who also directed HAIR and Jesus Christ Superstar on Broadway).<br /><br />This is not a mainstream, easy-to-take, studio film -- this is an aggressive, unsettling, glorious, deeply emotional, wildly imaginative piece of storytelling that you'll never forget. And it just might change the way you see the world...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \" Jim Abrahams\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5000050002750153,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lclm763QjQof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f9c15a-e1e9-402f-82f6-98cd13d09486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49999, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XEGp5XvijQof"
      },
      "outputs": [],
      "source": [
        "df = preprocess_data(df)\n",
        "vocab = {word: i for i, word in enumerate(set(word for tokens in df['tokens'] for word in tokens), 1)}\n",
        "embedding_matrix = create_embedding_matrix(vocab)\n",
        "\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=SEED)\n",
        "\n",
        "train_ds = IMDBDataset(train_df, vocab)\n",
        "val_ds = IMDBDataset(val_df, vocab)\n",
        "test_ds = IMDBDataset(test_df, vocab)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_ds, batch_size=64, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "l1cvuWUv6jeV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KJam2GfKjQog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca84194-4f24-49d4-9ca7-9525cd45ce46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-3d1ecbe60c0c>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = [torch.tensor(seq, dtype=torch.long) for seq in inputs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 0.5009, Train Acc = 0.7439, Val Loss = 0.3461, Val Acc = 0.8543\n",
            "Epoch 2: Train Loss = 0.3385, Train Acc = 0.8522, Val Loss = 0.3381, Val Acc = 0.8566\n",
            "Epoch 3: Train Loss = 0.2974, Train Acc = 0.8720, Val Loss = 0.2896, Val Acc = 0.8834\n",
            "Epoch 4: Train Loss = 0.2716, Train Acc = 0.8829, Val Loss = 0.2853, Val Acc = 0.8749\n",
            "Epoch 5: Train Loss = 0.2794, Train Acc = 0.8833, Val Loss = 0.4726, Val Acc = 0.8389\n",
            "Epoch 1: Train Loss = 0.5274, Train Acc = 0.7329, Val Loss = 0.7788, Val Acc = 0.7190\n",
            "Epoch 2: Train Loss = 0.4995, Train Acc = 0.7469, Val Loss = 0.3841, Val Acc = 0.8382\n",
            "Epoch 3: Train Loss = 0.3434, Train Acc = 0.8500, Val Loss = 0.3990, Val Acc = 0.8242\n",
            "Epoch 4: Train Loss = 0.3166, Train Acc = 0.8635, Val Loss = 0.5091, Val Acc = 0.7962\n",
            "Epoch 5: Train Loss = 0.3015, Train Acc = 0.8704, Val Loss = 0.2945, Val Acc = 0.8794\n",
            "Epoch 1: Train Loss = 0.5278, Train Acc = 0.7348, Val Loss = 0.7327, Val Acc = 0.6564\n",
            "Epoch 2: Train Loss = 0.3707, Train Acc = 0.8326, Val Loss = 0.4940, Val Acc = 0.7872\n",
            "Epoch 3: Train Loss = 0.3338, Train Acc = 0.8526, Val Loss = 0.5167, Val Acc = 0.7914\n",
            "Epoch 4: Train Loss = 0.3096, Train Acc = 0.8652, Val Loss = 0.2872, Val Acc = 0.8805\n",
            "Epoch 5: Train Loss = 0.2911, Train Acc = 0.8736, Val Loss = 0.2633, Val Acc = 0.8932\n",
            "Epoch 1: Train Loss = 0.5661, Train Acc = 0.7068, Val Loss = 0.4687, Val Acc = 0.7928\n",
            "Epoch 2: Train Loss = 0.4896, Train Acc = 0.7609, Val Loss = 0.5387, Val Acc = 0.7960\n",
            "Epoch 3: Train Loss = 0.3927, Train Acc = 0.8221, Val Loss = 0.5475, Val Acc = 0.8195\n",
            "Epoch 4: Train Loss = 0.3437, Train Acc = 0.8490, Val Loss = 0.3077, Val Acc = 0.8683\n",
            "Epoch 5: Train Loss = 0.3188, Train Acc = 0.8611, Val Loss = 0.2870, Val Acc = 0.8814\n",
            "Best Test Accuracy: 89.82%\n"
          ]
        }
      ],
      "source": [
        "best_model = None\n",
        "best_acc = 0\n",
        "for params in ParameterGrid(param_grid):\n",
        "    model = train_and_evaluate(params, embedding_matrix, train_loader, val_loader, test_loader, vocab_size=len(vocab) + 1)\n",
        "    acc = test_model(model, test_loader)\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model = model\n",
        "\n",
        "print(f'Best Test Accuracy: {best_acc * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}